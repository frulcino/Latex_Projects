\begin{frame}{Introduction to Coding Theory}
    Coding theory is the study of the properties of codes and their respective fitness for specific applications.
    \textcolor{red}{Why?}
    \begin{itemize}
        \item Retrieve information from corrupted messages
        \item Store data (which is just sending a message to your future self)
        \item Data compression
        \item Cryptography
    \end{itemize}
\end{frame}
\begin{frame}

    \vspace{-2cm} % Adjust the vertical space as needed
    \hspace{2.3cm}\textcolor{red}{How?}
    \begin{center}
        \alert<1>{\Huge Redundancy!} \\ \pause
        \alert<3>{\huge (Smartly)}
    \end{center}
    \pause
    Let's repeat each row of a message three times. If we obtain the message:
    
    \pause
    
    \only<3>{
    \begin{center}
         \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
        \hline
        0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 \\
        \hline
        0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0 \\
        \hline
        0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0 \\
        \hline
        \end{tabular}
    \end{center}
    }
    
    \only<4>{
    \begin{center}
         \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
        \hline
        0 & 0 & 0 & 1 & \cellcolor{red!20}0 & 1 & 0 & 0 & 0 \\
        \hline
        0 & 0 & 0 & 1 & \cellcolor{red!20} 1 & 1 & 0 & 0 & 0 \\
        \hline
        0 & 0 & 0 & 1 & \cellcolor{red!20} 1 & 1 & 0 & 0 & 0 \\
        \hline
        \end{tabular}
            
    \end{center}
    }
    
    \bigskip
    
    Since "1" appears twice and "0" once, we may assume more likely that the original message was:
    
    \bigskip
    
    \begin{center}
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
        \hline
        0 & 0 & 0 & 1 & \cellcolor{green!20} 1 & 1 & 0 & 0 & 0 \\
        \hline
    \end{tabular}
    \end{center}
    
    \bigskip
    
    But this way, we took three times the length of the message to correct one error!
    
    \bigskip
    
    \textcolor{gray}{Btw the message says SOS in Morse, so maybe go seek help?}
    \end{frame}
    
\begin{frame}{A better way to do it}
We rearrange the original message
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
    \hline
    \rowcolor{blue!20} 0 & 0 & 0 & 1 &  1 & 1 & 0 & 0 & 0 \\
    \hline
\end{tabular}
in a 4 by 4 grid: \\
\begin{center}

\begin{tabular}{|c|c|c|c|}
\hline
     &  \cellcolor{red!20} 0 & \cellcolor{red!20} 0 & \cellcolor{blue!20}  0  \\ \hline
    \cellcolor{red!20} 1 & \cellcolor{blue!20} 0 & \cellcolor{blue!20}  0 & \cellcolor{blue!20} 1  \\ \hline
    \cellcolor{red!20} 0 & \cellcolor{blue!20} 1 &\cellcolor{blue!20}  1 &\cellcolor{blue!20} 0  \\ \hline
    \rowcolor{blue!20}0 & 0 & 0 & 0  \\ \hline
\end{tabular}
\end{center}
Where the red cells are the four redundant bits which encode the parity of subsets of columns or rows in the following way. \\

\only<1>{   
\begin{minipage}{0.4\textwidth}
        \begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
          &  \cellcolor{red!35} 0 & 0 & \cellcolor{blue!20}  0  \\ \hline
        1 & \cellcolor{blue!20} 0 &  0 & \cellcolor{blue!40} 1  \\ \hline
        0 & \cellcolor{blue!40} 1 &  1 &\cellcolor{blue!20} 0  \\ \hline
        0 & \cellcolor{blue!20} 0 & 0 &  \cellcolor{blue!20} 0  \\ \hline
\end{tabular}
\end{center}
\end{minipage}
%
\begin{minipage}{0.4 \textwidth}
    \begin{center}
        \cell{0}{red!35} = \cell{1}{blue!40} + \cell{1}{blue!40}
    \end{center}
\end{minipage}
}
\only<2>{   
\begin{minipage}{0.4\textwidth}
        \begin{center}
    \begin{tabular}{|c|c|>{\columncolor{blue!20}}c|>{\columncolor{blue!20}}c|c|} 
    \hline
          &  0 & \cellcolor{red!30}0  &  0  \\ \hline
        1 & 0 &  0 & \cellcolor{blue!40}1  \\ \hline
        0 & 1 &  \cellcolor{blue!40}1 & 0  \\ \hline
        0 & 0 & 0 &  0  \\ \hline
\end{tabular}
\end{center}
\end{minipage}
%
\begin{minipage}{0.4 \textwidth}
    \begin{center}
        \cell{0}{red!35} = \cell{1}{blue!40} + \cell{1}{blue!40}
    \end{center}
\end{minipage}
}
\only<3>{   
\begin{minipage}{0.4\textwidth}
        \begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
          &  0 & 0 &  0  \\ \hline
        \rowcolor{blue!20} \cellcolor{red!30}1 & 0 &  0 & \cellcolor{blue!40}1  \\ \hline
        0 & 1 &  1 & 0  \\ \hline
        \rowcolor{blue!20} 0 & 0 & 0 &  0  \\ \hline
\end{tabular}
\end{center}
\end{minipage}
%
\begin{minipage}{0.4 \textwidth}
    \begin{center}
        \cell{1}{red!35} = \cell{1}{blue!40} 
    \end{center}
\end{minipage}
}
\only<4>{
\begin{minipage}{0.4\textwidth}
        \begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
          &  0 & 0 &  0  \\ \hline
        1 & 0 &  0 & 1  \\ \hline
        \rowcolor{blue!20} \cellcolor{red!35}0 & \cellcolor{blue!40} 1 &  \cellcolor{blue!40} 1 & 0  \\ \hline
        \rowcolor{blue!20} 0 & 0 & 0 &  0  \\ \hline
\end{tabular}
\end{center}
\end{minipage}
%
\begin{minipage}{0.4 \textwidth}
    \begin{center}
        \cell{0}{red!35} = \cell{1}{blue!40} + \cell{1}{blue!40}
    \end{center}
\end{minipage}
} \\
\bigskip
Since \(2^4 = \text{total number of bits} + (\text{case in which there is no error}) = 15 + 1\) and if there is up to one error, every redundant bit halvens the number the possible locations of where the error might be, we can always correct up to one error in the message.
\end{frame}
\begin{frame}{Hamming Codes}
    
    The subset of codes in $\bF_2^{15}$ constructed the same way are called Hamming Codes. We observe that if we sum two Hamming codes, it remains an Hamming code (that is the parity checks remain valid also for the result of the sum):

    \begin{minipage}{0.25\textwidth}
        \centering
        \begin{tabular}{|c|c|c|c|}
            \hline
            &  \cellcolor{red!20} 0 & \cellcolor{red!20} 0 & \cellcolor{blue!20}  1 \\ \hline
            \cellcolor{red!20} 0 & \cellcolor{blue!20} 0 & \cellcolor{blue!20}  0 & \cellcolor{blue!20} 1  \\ \hline
            \cellcolor{red!20} 1 & \cellcolor{blue!20} 0 &\cellcolor{blue!20}  1 &\cellcolor{blue!20} 1  \\ \hline
             \rowcolor{blue!20}0 & 1 & 0 & 0  \\ \hline
        \end{tabular}
    \end{minipage}
    %
    \begin{minipage}{0.05\textwidth}
    \centering
        \textbf{+}
    \end{minipage}
    %
    \begin{minipage}{0.25\textwidth}
    \centering
        \begin{tabular}{|c|c|c|c|}
            \hline
            &  \cellcolor{red!20} 0 & \cellcolor{red!20} 0 & \cellcolor{blue!20}  0 \\ \hline
            \cellcolor{red!20} 1 & \cellcolor{blue!20} 0 & \cellcolor{blue!20}  0 & \cellcolor{blue!20} 1  \\ \hline
            \cellcolor{red!20} 0 & \cellcolor{blue!20} 1 &\cellcolor{blue!20}  1 &\cellcolor{blue!20} 0  \\ \hline
             \rowcolor{blue!20}0 & 0 & 0 & 0  \\ \hline
        \end{tabular}
    \end{minipage}
    %
    \begin{minipage}{0.05\textwidth}
    \centering
        \textbf{=}
    \end{minipage}
%
    \begin{minipage}{0.25\textwidth}
    \centering
        \begin{tabular}{|c|c|c|c|}
            \hline
            &  \cellcolor{red!20} 0 & \cellcolor{red!20} 0 & \cellcolor{blue!20}  1 \\ \hline
            \cellcolor{red!20} 1 & \cellcolor{blue!20} 0 & \cellcolor{blue!20}  0 & \cellcolor{blue!20} 0  \\ \hline
            \cellcolor{red!20} 1 & \cellcolor{blue!20} 1 &\cellcolor{blue!20}  0 &\cellcolor{blue!20} 1  \\ \hline
             \rowcolor{blue!20}0 & 1 & 0 & 0  \\ \hline
        \end{tabular}
    \end{minipage} \\
\bigskip
     Thus, since we can choose the numbers inside the 11 blue cells arbitrarily they form a 11 dimensional linear subspace of $\bF_2^{15}$.  For this reason these codes are referred to as \textcolor{blue}{[15,11] Hamming Codes}.
     
\end{frame}

\begin{frame}
\begin{itemize}
    \item Note given a code in \(\bF^{15}_2\) by changing one bit we can always recover an Hamming Code. Thus what we are doing to correct a message is simply taking the closest valid message! 

    \item Using \textbf{nnd} we partition the message space into balls centered on the codewords. If we receive a message, then we simply look at what ball it is in and then the center of that ball is the most likely correct message (This is called \textcolor{blue}{nearest neighbour decoder (nnd)}).
    
    \item To decode as many messages as possible, we take the largest radius such that the balls remain disjoint. 
    \item This radius equals to \( \lfloor \frac{d-1}{2}\rfloor\) where \(d\) is \emph{the minimum distance} of the code (the set containing all the \(m\) codewords).

    \item The minimum distance \(d\) is a simple measure of the goodness of a code.
    %\item (If the bit errors are i.i.d. then the nnd equals the maximum likelyhood decoder.)
    
    
   

    %if we center around each codeword in the alphabet a ball of size r and the balls are disjoint then r represents the number of errors we can correct in a code! We want the biggest r given the size of an alphabet-----) Sphere Packing
    
\end{itemize}

\end{frame}

\begin{frame}{Classical Sphere Packing Results}

In coding theory, given a message length \(n\) and a minimum distance \(d\), a fundamental problem is to construct the largest code with minimum distance \(d\). This maximum size is denoted by \(A_q(n,d)\) or \(B_q(n,d)\) if only linear codes are considered.
\quad

\begin{theorem}[Hamming Bound] \label{hamming}
\(B_q(n,d) \leq A_q(n,d) \leq \frac{q^n}{\sum_{i=o}^t\binom{n}{i}(q-1)^i}\) \\

Where \(t \coloneqq \lfloor \frac{d-1}{2}\rfloor \).
\end{theorem}

\begin{theorem}[Singleton Bound] \label{singleton}
For \(d \leq b\), \( A_q(n,d) \leq q^{n-d+1}\). Further more if an \([n,k,d]\)
linear code over \(\mathbb{F}_q\) exists, then \(k \leq n-d+1  \).  
\end{theorem}


%\begin{frame}{In general}

% \begin{tikzpicture}[scale = 0.5]
%   % Draw a grid of points
%   \foreach \x in {0,...,16}
%     \foreach \y in {0,...,16}
%       \fill[black] (\x, \y) circle (2pt);

%     \foreach \x in {0,...,5}
%         \foreach \y in {0,...,5}
%             \fill[blue] (\x*3, \y*3) circle (3pt); 
              

%   % Color some points differently
%   \fill[red] (1,2) circle (2pt);
%   \fill[blue] (3,1) circle (2pt);

%   % Draw arrows between points
%   \draw[->, thick] (0,0) -- (1,2);
%   \draw[->, thick] (2,3) -- (3,1);
% \end{tikzpicture}
% %
\end{frame}
%drawing idea: to balls with half the radious of distance
\begin{frame}{Proof of Hamming bound}
Let \(\mathcal{C} \subset \mathbb{F}_q^n\) be a code. And let \(t\) be the maximum radius such that the union \(\cup_{c \in \cC}B_t(c)\) is disjoint. As in the euclidean case it can be seen that \(t\) must be half of the minimum distance, that is \(t = \lfloor \frac{d-1}{2}\rfloor\). Then \(|\cup_{c \in \cC}B_t(c)|\leq |\bF_q^n|=q^n\) and \(|\cup_{c \in \cC}B_t(c)| = |\cC|b_t\). Where \(b_t\) is the size of the ball of radious t. To conclude observe that \(b_t = \sum_{i=1}^ts_i\) where \(s_i\) is the size of the sphere of radious \(i\). The latter equals the number of way we can choose exactly \(i\) non null coordinates in a vector of lenght \(n\), thus \(s_i = \binom{n}{i}(q-1)^i\). Thus \(|\cup_{c \in \cC}B_t(c)| = |\cC|\sum_{i=1}^t \binom{n}{i}(q-1)^i \leq q^n \). By taking the maximum over \(|\cC|\) this concludes the proof.

% Let \(c,c' \in \cC\) be two distinct codewords with distance \(d\) and \(x \in B_t(c),x' \in B_t(x')\).
% Then \(d = d(c,c') \leq d(c,x) + d(x,x') + d(x',c') \leq t + 1 + t\). Thus \( \lfloor \frac{d-1}{2}\rfloor \leq t\). \(c,c'\) have exactly \(d\) different coordinates having indices \(i_1,\ldots,i_d\). Let \(x\) be the vector having coordinates \(x_j = c_j\) when \(j \neq i_1,\ldots,i_{\lfloor \frac{d-1}{2}\rfloor}\) and \(x_j = c'_j \) otherwise. Then \( d(x,c') =  \lfloor \frac{d-1}{2} \rfloor \leq t\) thus \(x \in B_t(c')\) and \(x \notin B_t(c)\). Thus \( t < d(x,c) = d - \lfloor \frac{d-1}{2}\rfloor = d + \lceil \frac{1-d}{2}\rceil = \lceil d +\frac{1-d}{2}\rceil= \lceil \frac{d+1}{2}\rceil\) thus \(t \leq \lfloor \frac{d-1}{2}\rfloor\).

\vspace{2cm}
We observe how knowing the sphere size was a central part of the proof.
\end{frame}

\begin{frame}{Other metrics}
   \begin{itemize}
   \item The Hamming metric is suitable when errors occur bit-wise with equal probability. For different error scenarios, alternative metrics must be considered. 
   
   \item
   For each metric it is important to try to get analogous results to \ref{hamming}  and \ref{singleton} bounds. 
   \item
   Generally each metric is studied individually.
   
   \item
   A different approach is to try to get analogous results on a family of metrics.
   \item In this presentation we show our results on the family of projective metrics.
   \end{itemize}
\end{frame}